% CNN Section

\subsection{Convolutional Neural Network (CNN)}
\begin{itemize}
    \item \textbf{Description:} Convolutional Neural Networks (CNNs) are deep learning models designed to process data with a grid-like topology, such as images. They use convolutional layers to automatically learn spatial hierarchies of features from input images.
    \item \textbf{Hyperparameters:} Number of layers, filter sizes, learning rate, batch size, dropout rate, optimizer.
    \item \textbf{Implementation:} Implemented using PyTorch's \texttt{nn.Module} and trained with the Adam optimizer.
\end{itemize}

% Add CNN training/validation results, confusion matrix, and any relevant figures or tables here.

\subsubsection{CNN hyperparameter tuning}

\textbf{Parameter Tuned:} Learning rate (see Table~\ref{tab:cnn-lr-tuning} and Figure~\ref{fig:cnn-lr})

The peak validation accuracy was achieved at a learning rate of 0.0001. After this point, the accuracy slightly decreased, indicating that lowering the learning rate further may have led to a steady decrease in accuracy.


% CNN learning rate tuning results
\begin{table}[h]
    \centering
    \caption{CNN Validation Accuracy for Different Learning Rates}
    \label{tab:cnn-lr-tuning}
    \begin{tabular}{cc}
        \toprule
        Learning Rate & Validation Accuracy (\%) \\
        \midrule
        0.1           & 74.8                     \\
        0.01          & 76.1                     \\
        0.001         & 74.5                     \\
        0.0001        & 80.0                     \\
        0.00001       & 79.9                     \\
        \bottomrule
    \end{tabular}
\end{table}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{images/cnn_lr.png}
    \caption{Validation accuracy for different learning rates.}
    \label{fig:cnn-lr}
\end{figure}


\textbf{Parameter Tuned:} Epochs (see Table~\ref{tab:cnn-tuning}, Table~\ref{tab:cnn-loss-epochs}, and Figure~\ref{fig:cnn-loss})

The loss is in a steady decline, indicating that the model is learning effectively. The model was stopped at 10 epochs to prevent overfitting.


% CNN training loss per epoch
\begin{table}[h]
    \centering
    \caption{CNN Training Loss for Different Epochs}
    \label{tab:cnn-loss-epochs}
    \begin{tabular}{cc}
        \toprule
        Epoch & Training Loss \\
        \midrule
        1     & 0.73          \\
        2     & 0.52          \\
        3     & 0.42          \\
        4     & 0.34          \\
        5     & 0.30          \\
        6     & 0.24          \\
        7     & 0.20          \\
        8     & 0.17          \\
        9     & 0.14          \\
        10    & 0.13          \\
        \bottomrule
    \end{tabular}
\end{table}

% CNN training loss curve
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{images/epoch_loss.png}
    \caption{Training loss per epoch for the CNN model.}
    \label{fig:cnn-loss}
\end{figure}


\subsubsection{Confusion Matrix for CNN (Figure~\ref{fig:cnn-cm})}
For this confusion matrix, the CNN model was trained for 10 epochs with a learning rate of 0.0001.

% CNN confusion matrix
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{images/cnn_confusion_matrix.png}
    \caption{Confusion matrix for the CNN model.}
    \label{fig:cnn-cm}
\end{figure}